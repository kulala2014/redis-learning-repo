# 深入理解 Kafka 可靠性：Offset、重试与幂等性

这篇文档将通过通俗易懂的比喻，深入解释 Kafka 中最难理解但也最重要的概念：**Offset 策略**与**幂等性**。

## 1. 核心比喻：读书与书签

为了理解 Kafka，我们可以把它想象成一本**不断在被作者（Producer）续写的小说**。

*   **Topic (Partition)**: 这本小说。
*   **Message**: 小说里的每一页。
*   **Offset**: 页码（第 1 页, 第 2 页...）。
*   **Consumer**: 读者（你）。
*   **Commit (提交)**: 你拿出一个**笔记本**，记下：“我读完第 10 页了”。

---

## 2. 灾难场景：为什么会重复？

假设你正在读第 11 页（内容是：“转账 100 元给张三”）。

1.  **读取**: 你读完了第 11 页，心里知道要转账了。
2.  **执行**: 你打开手机银行，给张三转了 100 元。
3.  **崩溃 (Crash)**: 就在你准备拿出笔记本记下“读完第 11 页”的前一秒，**你突然晕倒了（断电/宕机）**。
4.  **重启**: 过了几分钟，你醒了。
5.  **恢复进度**: 你拿出笔记本，发现上面最后一条记录是：“读完第 10 页”。
6.  **重复执行**: 于是，你以为第 11 页还没读，就翻到第 11 页又读了一遍：“转账 100 元给张三”。
7.  **后果**: 你又给张三转了 100 元。**张三收了两次钱！**

这就是 **At-Least-Once (至少一次)** 投递。Kafka 保证你肯定能读到第 11 页，但如果你没记下来就挂了，它会让你重读。

---

## 3. AutoOffsetReset：笔记本丢了怎么办？

`AutoOffsetReset` 配置的是：**当你完全找不到笔记本（没有 Offset 记录）时，该从哪里开始读？**

这种情况通常发生在：
1.  你的消费者组是全新的（第一次启动）。
2.  你的消费者组太久没上线，Kafka 把你的记录清除了（默认保留 7 天）。

### 策略 A: `Earliest` (从第一页开始)
*   **行为**: 你发现笔记本丢了，为了保险起见，你决定**从第 1 页开始，把整本书重读一遍**。
*   **后果**: 
    *   **好消息**: 你绝对不会漏掉任何情节。
    *   **坏消息**: 你会把以前处理过的几万个订单，全部重新处理一遍。
*   **适用**: **绝对不能丢数据**的核心业务（订单、支付）。

### 策略 B: `Latest` (从最新一页开始)
*   **行为**: 你发现笔记本丢了，你决定**只读作者现在新写出来的页**，之前的不管了。
*   **后果**:
    *   **好消息**: 省事，不用补作业。
    *   **坏消息**: 在你晕倒期间作者写的那 100 页精彩剧情，你永远错过了。
*   **适用**: **允许丢数据**的业务（日志、监控）。

---

## 4. 终极解决方案：幂等性 (Idempotency)

既然核心业务必须选 `Earliest`（或者默认的断点续传），那我们怎么解决“张三收两次钱”的问题呢？

答案是：**在执行动作之前，先查一下“流水账”。**

我们需要引入一个第三方的记账本（通常是 Redis 或 数据库），这个记账本要比 Offset 提交更可靠。

### 改造后的流程：

1.  **读取**: 读到第 11 页（Offset 11），内容是“转账 100 元给张三，**交易ID: TX-999**”。
2.  **检查 (幂等判断)**: 
    *   你去查 Redis: “`TX-999` 处理过吗？”
    *   Redis 说: “没处理过”。
3.  **执行**: 你给张三转账 100 元。
4.  **标记**: 你在 Redis 里写下: “`TX-999` 已处理”。
5.  **提交**: 你在笔记本上写下: “读完第 11 页”。

### 再次发生灾难：

1.  读到第 11 页。
2.  查 Redis: “没处理过”。
3.  转账。
4.  写 Redis: “`TX-999` 已处理”。
5.  **崩溃！** (还没来得及写笔记本)。
6.  **重启**。
7.  看笔记本：最后记录是第 10 页。
8.  **重读**: 翻到第 11 页。
9.  **检查 (幂等判断)**: 
    *   你去查 Redis: “`TX-999` 处理过吗？”
    *   Redis 说: **“处理过了！”**
10. **跳过**: 你直接翻篇，什么都不做。
11. **提交**: 补上笔记本记录：“读完第 11 页”。

**结果：张三只收到了一次钱。系统既没有丢数据，也没有重复执行。**

---

## 5. 代码模板 (.NET)

```csharp
public async Task ConsumeLoop(CancellationToken token)
{
    while (!token.IsCancellationRequested)
    {
        var result = consumer.Consume(token);
        var messageId = result.Message.Key; // 假设 Key 是唯一 ID
        
        // --- 幂等性检查 ---
        // 使用 Redis SetNX (Set if Not Exists) 锁住这个 ID
        // 如果返回 false，说明已经有别人（或者之前的我）处理过了
        bool isNew = await _redis.SetStringAsync(
            $"processed:{messageId}", 
            "1", 
            TimeSpan.FromDays(1), // 记录保留 1 天
            When.NotExists
        );

        if (!isNew)
        {
            _logger.LogInformation($"消息 {messageId} 重复，跳过。");
            // 即使跳过，也要 Commit，告诉 Kafka 这条消息我“处理”完了
            consumer.Commit(result); 
            continue;
        }

        // --- 业务逻辑 ---
        try 
        {
            await ProcessOrder(result.Message.Value);
            
            // --- 提交 Offset ---
            consumer.Commit(result);
        }
        catch (Exception ex)
        {
            // 如果业务失败，我们需要删除 Redis 里的记录，以便重试
            await _redis.KeyDeleteAsync($"processed:{messageId}");
            throw;
        }
    }
}
```
